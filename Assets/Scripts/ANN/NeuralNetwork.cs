//------------------------------------------------------------------------------
// <auto-generated>
//     이 코드는 도구를 사용하여 생성되었습니다.
//     런타임 버전:4.0.30319.34014
//
//     파일 내용을 변경하면 잘못된 동작이 발생할 수 있으며, 코드를 다시 생성하면
//     이러한 변경 내용이 손실됩니다.
// </auto-generated>
//------------------------------------------------------------------------------
using System;
using System.Collections.Generic;
using System.Linq;
namespace ANN
{
		[Serializable]
		public class NeuralNetwork
		{
		public double LearnRate { get; set; }
		public double Momentum { get; set; }
		public List<Neuron> InputLayer { get; set; }
		public List<Neuron> HiddenLayer { get; set; }
		public List<Neuron> OutputLayer { get; set; }
		static Random random = new Random();
//		public Dictionary<string, int> learningDic = new Dictionary<string, int>();
		
		public NeuralNetwork(int inputSize, int hiddenSize, int outputSize, double _learningRate)
		{
			//LearnRate = .2;
			LearnRate = _learningRate;
			Momentum = .04;
			InputLayer = new List<Neuron>();
			HiddenLayer = new List<Neuron>();
			OutputLayer = new List<Neuron>();
			
			for (int i = 0; i < inputSize; i++)
				InputLayer.Add(new Neuron());
			
			for (int i = 0; i < hiddenSize; i++)
				HiddenLayer.Add(new Neuron(InputLayer, true)); // use the sigmoid function
			
			for (int i = 0; i < outputSize; i++)
				OutputLayer.Add(new Neuron(HiddenLayer, true)); // use the identity function
		}
		
		public void Train(params double[] inputs)
		{
			int i = 0;
			InputLayer.ForEach(a => a.Value = inputs[i++]);
			HiddenLayer.ForEach(a => a.CalculateValue());
			OutputLayer.ForEach(a => a.CalculateValue());
		}
		
		public double[] Compute(params double[] inputs)
		{
			Train(inputs);
			return OutputLayer.Select(a => a.Value).ToArray();
		}
		
		public double CalculateError(params double[] targets)
		{
			int i = 0;
			return OutputLayer.Sum(a => Math.Abs(a.CalculateError(targets[i++])));
		}
		
		public void BackPropagate( double[] targets )
		{
			int i = 0;
			OutputLayer.ForEach(a => a.CalculateGradient(targets[i++])); //기울기 구하기 
			HiddenLayer.ForEach(a => a.CalculateGradient());
			HiddenLayer.ForEach(a => a.UpdateWeights(LearnRate, Momentum));
			OutputLayer.ForEach(a => a.UpdateWeights(LearnRate, Momentum));
			
		}
		
		public void printWeights(){
			UnityEngine.Debug.Log( "input weights in hidden layer ");
			int num = 0;
			foreach( Neuron n in HiddenLayer ){
				for( int j = 0; j < n.InputSynapses.Count; j++ )
					UnityEngine.Debug.Log ( "neuron" + num + "'s weight" + j + " : " + n.InputSynapses[j].Weight );
				num++;
			}
			UnityEngine.Debug.Log( "input weights in output layer ");
			num = 0;
			foreach( Neuron n in OutputLayer ){
				for( int j = 0; j < n.InputSynapses.Count; j++ )
					UnityEngine.Debug.Log ( "neuron" + num + "'s weight" + j + " : " + n.InputSynapses[j].Weight );
				num++;
			}
		}
		
		public static double NextRandom()
		{
			return 2 * random.NextDouble() - 1;
		}
		
		public static double SigmoidFunction(double x)
		{
			if (x < -45.0) return 0.0;
			else if (x > 45.0) return 1.0;
			return 1.0 / (1.0 + Math.Exp(-x));
		}
		
		public static double IdentityFunction(double x){
			return x;
		}
		
		public static double SigmoidDerivative(double f)
		{
			return f * (1 - f);
		}
		
		public static double IdentityDerivative(double f){
			return 1;
		}
		
		}
}

